{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting beautifulsoup4\n",
      "  Downloading beautifulsoup4-4.12.2-py3-none-any.whl (142 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.0/143.0 KB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting soupsieve>1.2\n",
      "  Downloading soupsieve-2.4.1-py3-none-any.whl (36 kB)\n",
      "Installing collected packages: soupsieve, beautifulsoup4\n",
      "Successfully installed beautifulsoup4-4.12.2 soupsieve-2.4.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1040/387707053.py:25: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  packages_section = topic_soup.find('h3', text='CRAN packages')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          package                                        package_url  \\\n",
      "0             abc  https://cran.r-project.org../packages/abc/inde...   \n",
      "1           abcrf  https://cran.r-project.org../packages/abcrf/in...   \n",
      "2        abglasso  https://cran.r-project.org../packages/abglasso...   \n",
      "3          abtest  https://cran.r-project.org../packages/abtest/i...   \n",
      "4        acebayes  https://cran.r-project.org../packages/acebayes...   \n",
      "...           ...                                                ...   \n",
      "4852   ganalytics  https://cran.r-project.org../packages/ganalyti...   \n",
      "4853      mathpix  https://cran.r-project.org../packages/mathpix/...   \n",
      "4854      radiant  https://cran.r-project.org../packages/radiant/...   \n",
      "4855      RStripe  https://cran.r-project.org../packages/RStripe/...   \n",
      "4856  transcribeR  https://cran.r-project.org../packages/transcri...   \n",
      "\n",
      "      category            topic  \\\n",
      "0      Regular         Bayesian   \n",
      "1      Regular         Bayesian   \n",
      "2      Regular         Bayesian   \n",
      "3      Regular         Bayesian   \n",
      "4      Regular         Bayesian   \n",
      "...        ...              ...   \n",
      "4852  Archived  WebTechnologies   \n",
      "4853  Archived  WebTechnologies   \n",
      "4854  Archived  WebTechnologies   \n",
      "4855  Archived  WebTechnologies   \n",
      "4856  Archived  WebTechnologies   \n",
      "\n",
      "                                              topic_url  \n",
      "0     https://cran.r-project.org/web/views/Bayesian....  \n",
      "1     https://cran.r-project.org/web/views/Bayesian....  \n",
      "2     https://cran.r-project.org/web/views/Bayesian....  \n",
      "3     https://cran.r-project.org/web/views/Bayesian....  \n",
      "4     https://cran.r-project.org/web/views/Bayesian....  \n",
      "...                                                 ...  \n",
      "4852  https://cran.r-project.org/web/views/WebTechno...  \n",
      "4853  https://cran.r-project.org/web/views/WebTechno...  \n",
      "4854  https://cran.r-project.org/web/views/WebTechno...  \n",
      "4855  https://cran.r-project.org/web/views/WebTechno...  \n",
      "4856  https://cran.r-project.org/web/views/WebTechno...  \n",
      "\n",
      "[4857 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Extract topic names and URLs\n",
    "main_url = 'https://cran.r-project.org/web/views/'\n",
    "response = requests.get(main_url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "topics_data = []\n",
    "topics_table = soup.find('table')\n",
    "\n",
    "for row in topics_table.find_all('tr')[1:]:\n",
    "    columns = row.find_all('td')\n",
    "    topic_name = columns[0].a.get_text()\n",
    "    topic_url = main_url + columns[0].a['href']\n",
    "    topics_data.append({'topic': topic_name, 'topic_url': topic_url})\n",
    "\n",
    "# Step 2: Extract package names and URLs for each topic\n",
    "packages_data = []\n",
    "for topic_data in topics_data:\n",
    "    response = requests.get(topic_data['topic_url'])\n",
    "    topic_soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    packages_section = topic_soup.find('h3', text='CRAN packages')\n",
    "    if packages_section:\n",
    "        packages_table = packages_section.find_next('table')\n",
    "        \n",
    "        for category_row in packages_table.find_all('tr')[1:]:\n",
    "            category_columns = category_row.find_all('td')\n",
    "            category = category_columns[0].i.get_text().strip(':')\n",
    "            \n",
    "            package_cells = category_columns[1].find_all('a')\n",
    "            \n",
    "            for package_cell in package_cells:\n",
    "                package_name = package_cell.get_text()\n",
    "                package_url = 'https://cran.r-project.org' + package_cell['href']\n",
    "                packages_data.append({\n",
    "                    'package': package_name,\n",
    "                    'package_url': package_url,\n",
    "                    'category': category,\n",
    "                    'topic': topic_data['topic'],\n",
    "                    'topic_url': topic_data['topic_url']\n",
    "                })\n",
    "\n",
    "\n",
    "# Step 3: Create a data frame\n",
    "df = pd.DataFrame(packages_data)\n",
    "\n",
    "# Display the resulting data frame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1040/1355324822.py:25: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  packages_section = topic_soup.find('h3', text='CRAN packages')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame saved as cran_packages.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Extract topic names and URLs\n",
    "main_url = 'https://cran.r-project.org/web/views/'\n",
    "response = requests.get(main_url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "topics_data = []\n",
    "topics_table = soup.find('table')\n",
    "\n",
    "for row in topics_table.find_all('tr')[1:]:\n",
    "    columns = row.find_all('td')\n",
    "    topic_name = columns[0].a.get_text()\n",
    "    topic_url = main_url + columns[0].a['href']\n",
    "    topics_data.append({'topic': topic_name, 'topic_url': topic_url})\n",
    "\n",
    "# Step 2: Extract package names and URLs for each topic\n",
    "packages_data = []\n",
    "for topic_data in topics_data:\n",
    "    response = requests.get(topic_data['topic_url'])\n",
    "    topic_soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    packages_section = topic_soup.find('h3', text='CRAN packages')\n",
    "    if packages_section:\n",
    "        packages_table = packages_section.find_next('table')\n",
    "        \n",
    "        for category_row in packages_table.find_all('tr'):\n",
    "            category_cells = category_row.find_all('td')\n",
    "            if len(category_cells) == 2:\n",
    "                category = category_cells[0].i.get_text().strip(':')\n",
    "                package_cells = category_cells[1].find_all('a')\n",
    "                \n",
    "                for package_cell in package_cells:\n",
    "                    package_name = package_cell.get_text()\n",
    "                    package_url = 'https://cran.r-project.org' + package_cell['href']\n",
    "                    packages_data.append({\n",
    "                        'package': package_name,\n",
    "                        'package_url': package_url,\n",
    "                        'category': category,\n",
    "                        'topic': topic_data['topic'],\n",
    "                        'topic_url': topic_data['topic_url']\n",
    "                    })\n",
    "\n",
    "# Step 3: Create a data frame\n",
    "df = pd.DataFrame(packages_data)\n",
    "\n",
    "# Save the DataFrame as CSV\n",
    "csv_filename = 'cran_packages.csv'\n",
    "df.to_csv(csv_filename, index=False)\n",
    "\n",
    "print(f\"DataFrame saved as {csv_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>package</th>\n",
       "      <th>package_url</th>\n",
       "      <th>category</th>\n",
       "      <th>topic</th>\n",
       "      <th>topic_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>arm</td>\n",
       "      <td>https://cran.r-project.org../packages/arm/inde...</td>\n",
       "      <td>Core</td>\n",
       "      <td>Bayesian</td>\n",
       "      <td>https://cran.r-project.org/web/views/Bayesian....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BACCO</td>\n",
       "      <td>https://cran.r-project.org../packages/BACCO/in...</td>\n",
       "      <td>Core</td>\n",
       "      <td>Bayesian</td>\n",
       "      <td>https://cran.r-project.org/web/views/Bayesian....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bayesforecast</td>\n",
       "      <td>https://cran.r-project.org../packages/bayesfor...</td>\n",
       "      <td>Core</td>\n",
       "      <td>Bayesian</td>\n",
       "      <td>https://cran.r-project.org/web/views/Bayesian....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bayesm</td>\n",
       "      <td>https://cran.r-project.org../packages/bayesm/i...</td>\n",
       "      <td>Core</td>\n",
       "      <td>Bayesian</td>\n",
       "      <td>https://cran.r-project.org/web/views/Bayesian....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>boa</td>\n",
       "      <td>https://cran.r-project.org../packages/boa/inde...</td>\n",
       "      <td>Core</td>\n",
       "      <td>Bayesian</td>\n",
       "      <td>https://cran.r-project.org/web/views/Bayesian....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5161</th>\n",
       "      <td>ganalytics</td>\n",
       "      <td>https://cran.r-project.org../packages/ganalyti...</td>\n",
       "      <td>Archived</td>\n",
       "      <td>WebTechnologies</td>\n",
       "      <td>https://cran.r-project.org/web/views/WebTechno...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5162</th>\n",
       "      <td>mathpix</td>\n",
       "      <td>https://cran.r-project.org../packages/mathpix/...</td>\n",
       "      <td>Archived</td>\n",
       "      <td>WebTechnologies</td>\n",
       "      <td>https://cran.r-project.org/web/views/WebTechno...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5163</th>\n",
       "      <td>radiant</td>\n",
       "      <td>https://cran.r-project.org../packages/radiant/...</td>\n",
       "      <td>Archived</td>\n",
       "      <td>WebTechnologies</td>\n",
       "      <td>https://cran.r-project.org/web/views/WebTechno...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5164</th>\n",
       "      <td>RStripe</td>\n",
       "      <td>https://cran.r-project.org../packages/RStripe/...</td>\n",
       "      <td>Archived</td>\n",
       "      <td>WebTechnologies</td>\n",
       "      <td>https://cran.r-project.org/web/views/WebTechno...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5165</th>\n",
       "      <td>transcribeR</td>\n",
       "      <td>https://cran.r-project.org../packages/transcri...</td>\n",
       "      <td>Archived</td>\n",
       "      <td>WebTechnologies</td>\n",
       "      <td>https://cran.r-project.org/web/views/WebTechno...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5166 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            package                                        package_url  \\\n",
       "0               arm  https://cran.r-project.org../packages/arm/inde...   \n",
       "1             BACCO  https://cran.r-project.org../packages/BACCO/in...   \n",
       "2     bayesforecast  https://cran.r-project.org../packages/bayesfor...   \n",
       "3            bayesm  https://cran.r-project.org../packages/bayesm/i...   \n",
       "4               boa  https://cran.r-project.org../packages/boa/inde...   \n",
       "...             ...                                                ...   \n",
       "5161     ganalytics  https://cran.r-project.org../packages/ganalyti...   \n",
       "5162        mathpix  https://cran.r-project.org../packages/mathpix/...   \n",
       "5163        radiant  https://cran.r-project.org../packages/radiant/...   \n",
       "5164        RStripe  https://cran.r-project.org../packages/RStripe/...   \n",
       "5165    transcribeR  https://cran.r-project.org../packages/transcri...   \n",
       "\n",
       "      category            topic  \\\n",
       "0         Core         Bayesian   \n",
       "1         Core         Bayesian   \n",
       "2         Core         Bayesian   \n",
       "3         Core         Bayesian   \n",
       "4         Core         Bayesian   \n",
       "...        ...              ...   \n",
       "5161  Archived  WebTechnologies   \n",
       "5162  Archived  WebTechnologies   \n",
       "5163  Archived  WebTechnologies   \n",
       "5164  Archived  WebTechnologies   \n",
       "5165  Archived  WebTechnologies   \n",
       "\n",
       "                                              topic_url  \n",
       "0     https://cran.r-project.org/web/views/Bayesian....  \n",
       "1     https://cran.r-project.org/web/views/Bayesian....  \n",
       "2     https://cran.r-project.org/web/views/Bayesian....  \n",
       "3     https://cran.r-project.org/web/views/Bayesian....  \n",
       "4     https://cran.r-project.org/web/views/Bayesian....  \n",
       "...                                                 ...  \n",
       "5161  https://cran.r-project.org/web/views/WebTechno...  \n",
       "5162  https://cran.r-project.org/web/views/WebTechno...  \n",
       "5163  https://cran.r-project.org/web/views/WebTechno...  \n",
       "5164  https://cran.r-project.org/web/views/WebTechno...  \n",
       "5165  https://cran.r-project.org/web/views/WebTechno...  \n",
       "\n",
       "[5166 rows x 5 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Credentials to database connection\n",
    "hostname=\"oss-1.cij9gk1eehyr.us-east-1.rds.amazonaws.com\"\n",
    "dbname=\"cran\"\n",
    "uname=\n",
    "pwd=\n",
    "\n",
    "# Create SQLAlchemy engine to connect to MySQL Database\n",
    "engine = create_engine(\"mysql+pymysql://{user}:{pw}@{host}/{db}\"\n",
    "\t\t\t\t.format(host=hostname, db=dbname, user=uname, pw=pwd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5166"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.to_sql('package_categories', engine, if_exists='replace')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
